# Practica_1_Web_scraping

## Contexto. Explicar en qué contexto se ha recolectado la información. Explique por qué el sitio web elegido proporciona dicha información.

Teniendo en cuenta el momento convulso que estamos viviendo como consecuencia de la sentencia de los políticos catalanes, la idea de este trabajo ha sido recolectar la información que nos ofrecen los principales períodicos nacionales durantes los días 13/10/2019 al 20/10/2019. Se recopilarán todas las noticias de las ediciones impresas de los periódicos escogidos, para posteriormente poder analizarlas de manera más pormenorizada, e incluso poder comparar entre diferentes medios de comunicación. Aunque en un primer momento el interés este centrado en las noticias que versan sobre el juicio del proces, los altercados y las manifestaciones que están teniendo lugar en Catalunya y el resto del estado español, se recogerán todas las noticias porque también puede resultar interesante analizar la proporción de las noticias que versan sobre este tema en comparación con los demás temas en los diferentes medios de comunicación.

## Definir un título para el dataset. Elegir un título que sea descriptivo.

Noticias de los principales periódicos españoles entre el 13 y el 20 de octubre del 2019.

## Descripción del dataset. Desarrollar una descripción breve del conjunto de datos que se ha extraído (es necesario que esta descripción tenga sentido con el título elegido).

Esto lo haríamos una vez que tengamos la base de datos. Pondríamos cuantas noticias se han recuperado, cuantas de cada periódico, cuantos al día...

## Representación gráfica. Presentar una imagen o esquema que identifique el dataset visualmente.

Aquí haríamos por ejemplo los diagramas de barras.

## Contenido. Explicar los campos que incluye el dataset, el periodo de tiempo de los datos y cómo se ha recogido.

La base de datos contiene información de las noticias publicadas entre los días 13/10/2019 al 20/10/2019 por los periódicos "La vanguardia" y "El mundo". La estructura de la base de datos se ha organizado de manera que cada fila es una noticia. De cada noticia tenemos los siguientes datos:

    El periódico de donde se ha recogido la noticia.
    El día en el que se ha publicado la noticia (en formato dd/mm/aaaa).
    El campo o la sección a la que pertence la noticia (sería una variable de tipo cadena, aunque la idea es crear categorías más o menos comunes entre los diferentes periódicos)
    El titular de la noticia (sería una variable de tipo cadena)
    El cuerpo de la noticia (sería una variable de tipo cadena)

## Agradecimientos. Presentar al propietario del conjunto de datos. Es necesario incluir citas de investigación o análisis anteriores (si los hay).

No tengo ni idea de lo que quiere decir esto

## Inspiración. Explique por qué es interesante este conjunto de datos y qué preguntas se pretenden responder.

Aquí podremos ir poniendo lo que encontremos una vez que tengamos los datos.

## Licencia. Seleccione una de estas licencias para su dataset y explique el motivo de su selección:

    Released Under CC0: Public Domain License
    Released Under CC BY-NC-SA 4.0 License
    Released Under CC BY-SA 4.0 License
    Database released under Open Database License, individual contents under Database Contents License
    Other (specified above)
    Unknown License

## Código. Adjuntar el código con el que se ha generado el dataset, preferiblemente en Python o, alternativamente, en R.

En nuestro caso adjuntaríamos el código en R

## Dataset. Presentar el dataset en formato CSV
